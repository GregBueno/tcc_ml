{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify TXT Describe Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dir_csv+'maint_order'+\".txt\", \"r\",encoding='utf-8')\n",
    "tt = f.read()\n",
    "tt = tt.replace(\"\\t\", \" \")\n",
    "tt = tt.replace(\"\\n\", \" \")\n",
    "tt = tt.split('{')\n",
    "\n",
    "k = []\n",
    "for i in tt:\n",
    "    y = []\n",
    "    for t in i.split(','):\n",
    "        u = t.strip()\n",
    "        if any(c in u for c in ['desc','name','type','useNull']):\n",
    "            try:\n",
    "                u1 = u.split(':')\n",
    "                u2 = u1[1].strip()\n",
    "                if len(re.findall(r\"(?<=\\')(.*?)(?=\\')\",u2)) > 0:\n",
    "                    u3 = re.findall(r\"(?<=\\')(.*?)(?=\\')\",u2)\n",
    "                if len(re.findall(r'(?<=\\\")(.*?)(?=\\\")',u2)) > 0:\n",
    "                    u3 = re.findall(r'(?<=\\\")(.*?)(?=\\\")',u2)\n",
    "                if u2[:5].strip() in ['true','false']:\n",
    "                    u3 = [ u2[:5].strip() ] \n",
    "                else:\n",
    "                    pass\n",
    "                y.append(u3[0])\n",
    "            except:\n",
    "                pass\n",
    "    if len(y) == 4:\n",
    "        k.append(y)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "data_extrac = pd.DataFrame(k)\n",
    "data_extrac = data_extrac.rename(columns={data_extrac.columns[0]: 'desc',data_extrac.columns[1]: 'col',data_extrac.columns[2]: 'type', data_extrac.columns[3]: 'usenull'})\n",
    "data_extrac['usenull'] = data_extrac['usenull'].astype(bool)\n",
    "data_extrac['usenull'] = data_extrac['usenull'].astype(int)\n",
    "data_extrac = data_extrac[:126]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config/tipocampopeso.json') as f:\n",
    "    dict_type = json.load(f)\n",
    "\n",
    "df_type = pd.DataFrame.from_dict(dict_type['type'],orient='index').reset_index()\n",
    "df_type = df_type.rename(columns={'index':'type',0:'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(data_extrac,df_type,on=['type'],how='left')\n",
    "df_merge = df_merge.rename(columns={'value':'typevalue'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFile = './base_manusis/evaluation/maint_order.csv'\n",
    "df_eval = pd.read_csv(pathFile, delimiter=';')\n",
    "df_merge = df_merge[df_merge.col.isin(df_eval.columns)]\n",
    "df_merge = df_merge[['col','typevalue','usenull']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns\n",
    "# list(set(df_merge.name.unique()) - set(df_eval.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_csv = \"./base_manusis/original/\"\n",
    "dir_save = \"./base_manusis/preprocess_new/\"\n",
    "table = \"maint_order\"\n",
    "\n",
    "data = pd.read_csv(dir_csv+table+\".csv\",low_memory=False)\n",
    "\n",
    "# profile = pandas_profiling.ProfileReport(data)\n",
    "# profile.to_file(output_file=dir_csv+table+\"_describe.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['opened_at'] = pd.to_datetime(data['opened_at'], errors = 'coerce')\n",
    "start_date = '01-01-2017'\n",
    "end_date = '12-31-2019'\n",
    "mask = (data['opened_at'] > start_date) & (data['opened_at'] <= end_date)\n",
    "data = data.loc[mask]\n",
    "\n",
    "data['description'] = data['description'].str.lower()\n",
    "data['user_text'] = data['user_text'].str.lower()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterize(df, columns):\n",
    "    \"\"\"\n",
    "    Extratify data missing values, diverity in values and count rows of max class\n",
    "    \"\"\"\n",
    "    df = df[columns]\n",
    "    \n",
    "    info = [['col','qt_missing','qt_diversity','qt_max_row_class','p_null','p_unique','p_max_row_class']]\n",
    "    \n",
    "    tot_rows, _ = data.shape\n",
    "    \n",
    "    \n",
    "    for col in columns:\n",
    "        try:\n",
    "            # Qtde Valores Nulos\n",
    "            missing = df[col].isna().sum()\n",
    "            \n",
    "            # Qtde de classes diferentes\n",
    "            diversity = len(df[col].unique()) \n",
    "\n",
    "            # Qtde de registros para maior classe\n",
    "            max_row_class = df.groupby([col]).size().reset_index(name='count').sort_values(by=['count'],ascending=False)['count'].max()\n",
    "             \n",
    "            info.append([col, missing, diversity, max_row_class, missing/tot_rows, diversity/tot_rows, max_row_class/tot_rows])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    df_aux = pd.DataFrame(info[1:],columns=info[0])\n",
    "    \n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = counterize(data,data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.merge(df_analysis,df_merge,on='col',how='left').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result[['col','typevalue','usenull','p_null','p_unique','p_max_row_class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result to Imput in TOPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('./resource/imput_topsis.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data to ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[*list(df_result.col.values)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./resource/maint_order_process.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis.to_csv('./base_manusis/analysis/'+table+'.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis.sort_values(by=['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns based in condition\n",
    "\n",
    "# df_select = df_analysis.query(\"pr_missing<0.5 and pr_diversity <0.5 and pr_max_row_class<0.8\").sort_values(by=['pr_max_row_class'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = df_select.col.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(select_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_full = data[list(select_cols)]\n",
    "\n",
    "list_exclude = ['cancel_user_id','origin_doc','prog_year_week_number','maint_order_cancel_reason_id',\n",
    "                'total_cost','rpn','what','when','who','why','how','maint_order_on_hold_reason_id','performed_worktime',\n",
    "                'estimated_worktime','performed_asset_downtime','id_mobile','mobile_uuid','rework_cos','index',\n",
    "                'priority_calculated','maint_req_priority','maint_req_id',\n",
    "                'user_text','scheduled_to_origin','est_finish_at','scheduled_to','est_finish_at_origin','logged_user_id']\n",
    "\n",
    "for i in list_exclude:\n",
    "    try:\n",
    "        df_table_full = df_table_full.drop(i, axis=1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_table_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_table_full.groupby(['priority','maint_order_status_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_table_full.to_csv(dir_save+table+\"_etl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de campos a desconsiderar\n",
    "typeNotConsider = ['date','datetime','string','text']\n",
    "# Tabela para processar\n",
    "table = \"maint_order\"\n",
    "# maint_req , maint_order\n",
    "#============================================\n",
    "\n",
    "dir_csv = \"./base_manusis/original/\"\n",
    "dir_save = \"./base_manusis/preprocess/\"\n",
    "\n",
    "data = pd.read_csv(dir_csv+table+\".csv\",low_memory=False)\n",
    "\n",
    "data['opened_at'] = pd.to_datetime(data['opened_at'], errors = 'coerce')\n",
    "start_date = '01-01-2017'\n",
    "end_date = '12-31-2019'\n",
    "mask = (data['opened_at'] > start_date) & (data['opened_at'] <= end_date)\n",
    "data = data.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_describe = data_extrac[['desc','type']].groupby(['type']).count()\n",
    "# columns = data_extrac['name'].tolist()\n",
    "\n",
    "# data_extrac = data_extrac[data_extrac['name'].isin(list(data.columns.values))]\n",
    "# select_columns = data_extrac[~data_extrac['type'].isin(typeNotConsider)]\n",
    "# select_columns = select_columns['name'].tolist()\n",
    "\n",
    "# data_select = data[select_columns].fillna(0)\n",
    "\n",
    "# list_columns = set(data_select.columns)\n",
    "# list_columns_select = []\n",
    "\n",
    "# for x in list_columns:\n",
    "#     data_select[x] = data_select[x].astype('category')\n",
    "#     if len(data_select[x].dtype.categories) > 1 and any(data_select[x].duplicated()):\n",
    "#         list_columns_select.append(x)\n",
    "# data_select = data_select[list_columns_select]\n",
    "\n",
    "# data_select = data_select.drop('estimated_worktime', axis=1)\n",
    "# data_select = data_select.drop('performed_asset_downtime', axis=1)\n",
    "# data_select = data_select.drop('performed_worktime', axis=1)\n",
    "# data_select = data_select.drop('priority_calculated', axis=1)\n",
    "# data_select = data_select.drop('maint_req_priority', axis=1)\n",
    "# data_select = data_select.drop('maint_req_id', axis=1)\n",
    "\n",
    "# list_exclude = ['cancel_user_id','origin_doc','prog_year_week_number','maint_order_cancel_reason_id',\n",
    "#                 'total_cost','rpn','what','when','who','why','how','maint_order_on_hold_reason_id','performed_worktime',\n",
    "#                 'estimated_worktime','performed_asset_downtime','id_mobile','mobile_uuid','rework_cos','index',\n",
    "#                 'priority_calculated','maint_req_priority','maint_req_id']\n",
    "\n",
    "# for i in list_exclude:\n",
    "#     try:\n",
    "#         data_select = data_select.drop(i, axis=1)\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "# data_select.to_csv(dir_save+table+\"_etl.csv\", index=False)\n",
    "# profile = pandas_profiling.ProfileReport(data_select)\n",
    "# profile.to_file(outputfile=dir_save+table+\"_describe.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_table_full.groupby(['user_text']).size()\n",
    "# df_table_full[df_table_full['user_text'].str.contains(\"testes\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df_table_full.columns:\n",
    "#     print(column)\n",
    "#     display(df_table_full.groupby([column]).size().reset_index(name='count').sort_values(by=['count'],ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_percentage(df, columns):\n",
    "    \"\"\"\n",
    "    This function returns the number of different elements in each column as a percentage of the total elements in the group.\n",
    "    A low value indicates there are many repeated elements.\n",
    "    Example 1: a value of 0 indicates all values are the same.\n",
    "    Example 2: a value of 100 indicates all values are different.\n",
    "    \"\"\"\n",
    "    diversity = dict()\n",
    "\n",
    "    for col in columns:\n",
    "        diversity[col] = len(df[col].unique())\n",
    "\n",
    "    diversity_series = pd.Series(diversity)\n",
    "    return (diversity_series/len(df)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_percentage(df_table_full,df_table_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = data.isna().mean()\n",
    "total_missing = data.isna().sum()\n",
    "\n",
    "missing_value_df = pd.DataFrame({'column_name': data.columns,\n",
    "                                 'total_missing': total_missing,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df = missing_value_df.reset_index();\n",
    "missing_value_df = missing_value_df.drop('index',axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
