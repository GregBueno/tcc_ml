{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 70\n",
    "\n",
    "# Tipos de campos a desconsiderar\n",
    "typeNotConsider = ['date','datetime','string','text']\n",
    "# Tabela para processar\n",
    "table = \"maint_order\"\n",
    "# maint_req , maint_order\n",
    "\n",
    "#============================================\n",
    "\n",
    "dir_csv = \"./base_manusis/original/\"\n",
    "dir_save = \"./base_manusis/preprocess/\"\n",
    "\n",
    "data = pd.read_csv(dir_csv+table+\".csv\",low_memory=False)\n",
    "\n",
    "data['opened_at'] = pd.to_datetime(data['opened_at'], errors = 'coerce')\n",
    "start_date = '01-01-2017'\n",
    "end_date = '12-31-2019'\n",
    "mask = (data['opened_at'] > start_date) & (data['opened_at'] <= end_date)\n",
    "data = data.loc[mask]\n",
    "\n",
    "# profile = pandas_profiling.ProfileReport(data)\n",
    "# profile.to_file(output_file=dir_csv+table+\"_describe.html\")\n",
    "\n",
    "f = open(dir_csv+table+\".txt\", \"r\",encoding='utf-8')\n",
    "tt = f.read()\n",
    "tt = tt.replace(\"\\t\", \" \")\n",
    "tt = tt.replace(\"\\n\", \" \")\n",
    "tt = tt.split('{')\n",
    "\n",
    "k = []\n",
    "for i in tt:\n",
    "    y = []\n",
    "    for t in i.split(','):\n",
    "        u = t.strip()\n",
    "        if any(c in u for c in ['desc','name','type']):\n",
    "            try:\n",
    "                u1 = u.split(':')\n",
    "                u2 = u1[1].strip()\n",
    "                if len(re.findall(r\"(?<=\\')(.*?)(?=\\')\",u2)) > 0:\n",
    "                    u3 = re.findall(r\"(?<=\\')(.*?)(?=\\')\",u2)\n",
    "                if len(re.findall(r'(?<=\\\")(.*?)(?=\\\")',u2)) > 0:\n",
    "                    u3 = re.findall(r'(?<=\\\")(.*?)(?=\\\")',u2)\n",
    "                else:\n",
    "                    pass\n",
    "                y.append(u3[0])\n",
    "            except:\n",
    "                pass\n",
    "    if len(y) == 3:\n",
    "        k.append(y)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "data_extrac = pd.DataFrame(k)\n",
    "data_extrac = data_extrac.rename(columns={data_extrac.columns[0]: 'desc',data_extrac.columns[1]: 'name',data_extrac.columns[2]: 'type'})\n",
    "data_describe = data_extrac[['desc','type']].groupby(['type']).count()\n",
    "columns = data_extrac['name'].tolist()\n",
    "\n",
    "data_extrac = data_extrac[data_extrac['name'].isin(list(data.columns.values))]\n",
    "select_columns = data_extrac[~data_extrac['type'].isin(typeNotConsider)]\n",
    "select_columns = select_columns['name'].tolist()\n",
    "\n",
    "data_select = data[select_columns].fillna(0)\n",
    "\n",
    "list_columns = set(data_select.columns)\n",
    "list_columns_select = []\n",
    "\n",
    "for x in list_columns:\n",
    "    data_select[x] = data_select[x].astype('category')\n",
    "    if len(data_select[x].dtype.categories) > 1 and any(data_select[x].duplicated()):\n",
    "        list_columns_select.append(x)\n",
    "data_select = data_select[list_columns_select]\n",
    "\n",
    "data_select = data_select.drop('estimated_worktime', axis=1)\n",
    "data_select = data_select.drop('performed_asset_downtime', axis=1)\n",
    "data_select = data_select.drop('performed_worktime', axis=1)\n",
    "data_select = data_select.drop('priority_calculated', axis=1)\n",
    "data_select = data_select.drop('maint_req_priority', axis=1)\n",
    "data_select = data_select.drop('maint_req_id', axis=1)\n",
    "\n",
    "list_exclude = ['cancel_user_id','origin_doc','prog_year_week_number','maint_order_cancel_reason_id',\n",
    "                'total_cost','rpn','what','when','who','why','how','maint_order_on_hold_reason_id','performed_worktime',\n",
    "                'estimated_worktime','performed_asset_downtime','id_mobile','mobile_uuid','rework_cos','index',\n",
    "                'priority_calculated','maint_req_priority','maint_req_id']\n",
    "\n",
    "for i in list_exclude:\n",
    "    try:\n",
    "        data_select = data_select.drop(i, axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "data_select.to_csv(dir_save+table+\"_etl.csv\", index=False)\n",
    "profile = pandas_profiling.ProfileReport(data_select)\n",
    "profile.to_file(outputfile=dir_save+table+\"_describe.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "dir_csv = \"./base_manusis/original/\"\n",
    "dir_save = \"./base_manusis/preprocess_slim/\"\n",
    "table = \"maint_order\"\n",
    "\n",
    "data = pd.read_csv(dir_csv+table+\".csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193005, 113)\n"
     ]
    }
   ],
   "source": [
    "data['opened_at'] = pd.to_datetime(data['opened_at'], errors = 'coerce')\n",
    "start_date = '01-01-2017'\n",
    "end_date = '12-31-2019'\n",
    "mask = (data['opened_at'] > start_date) & (data['opened_at'] <= end_date)\n",
    "data = data.loc[mask]\n",
    "\n",
    "data['description'] = data['description'].str.lower()\n",
    "data['user_text'] = data['user_text'].str.lower()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterize(df, columns):\n",
    "    \"\"\"\n",
    "    Extratify data missing values, diverity in values and count rows of max class\n",
    "    \"\"\"\n",
    "    df = df[columns]\n",
    "    \n",
    "    info = [['col','qt_missing','qt_diversity','qt_max_row_class','pr_missing','pr_diversity','pr_max_row_class']]\n",
    "    \n",
    "    tot_rows, _ = data.shape\n",
    "    \n",
    "    \n",
    "    for col in columns:\n",
    "        try:\n",
    "            # Qtde Valores Nulos\n",
    "            missing = df[col].isna().sum()\n",
    "            \n",
    "            # Qtde de classes diferentes\n",
    "            diversity = len(df[col].unique()) \n",
    "\n",
    "            # Qtde de registros para maior classe\n",
    "            max_row_class = df.groupby([col]).size().reset_index(name='count').sort_values(by=['count'],ascending=False)['count'].max()\n",
    "             \n",
    "            info.append([col, missing, diversity, max_row_class, missing/tot_rows, diversity/tot_rows, max_row_class/tot_rows])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    df_aux = pd.DataFrame(info[1:],columns=info[0])\n",
    "    \n",
    "    return df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df to analysis values\n",
    "df_analysis = counterize(data,data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis.sort_values(by=['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns based in condition\n",
    "df_select = df_analysis.query(\"pr_missing<0.5 and pr_diversity <0.5 and pr_max_row_class<0.8\").sort_values(by=['pr_max_row_class'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = df_select.col.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_full = data[list(select_cols)]\n",
    "\n",
    "list_exclude = ['cancel_user_id','origin_doc','prog_year_week_number','maint_order_cancel_reason_id',\n",
    "                'total_cost','rpn','what','when','who','why','how','maint_order_on_hold_reason_id','performed_worktime',\n",
    "                'estimated_worktime','performed_asset_downtime','id_mobile','mobile_uuid','rework_cos','index',\n",
    "                'priority_calculated','maint_req_priority','maint_req_id',\n",
    "                'user_text','scheduled_to_origin','est_finish_at','scheduled_to','est_finish_at_origin','logged_user_id']\n",
    "\n",
    "for i in list_exclude:\n",
    "    try:\n",
    "        df_table_full = df_table_full.drop(i, axis=1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>third_loc_id</th>\n",
       "      <th>second_loc_id</th>\n",
       "      <th>cost_center_id</th>\n",
       "      <th>asset_group_id</th>\n",
       "      <th>first_loc_id</th>\n",
       "      <th>area_id</th>\n",
       "      <th>maint_service_type_id</th>\n",
       "      <th>maint_order_activities_type</th>\n",
       "      <th>is_sistematic</th>\n",
       "      <th>priority</th>\n",
       "      <th>maint_order_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7399.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>379.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7161.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7191.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asset_id  third_loc_id  second_loc_id  cost_center_id  asset_group_id  \\\n",
       "19     7399.0           NaN          350.0            38.0           113.0   \n",
       "20     7399.0           NaN          350.0            38.0           113.0   \n",
       "21      379.0         106.0           18.0            15.0            59.0   \n",
       "144    7161.0         326.0          238.0            22.0           112.0   \n",
       "145    7191.0         335.0          239.0            22.0           112.0   \n",
       "\n",
       "     first_loc_id  area_id  maint_service_type_id  \\\n",
       "19          349.0        3                      4   \n",
       "20          349.0        3                      4   \n",
       "21           13.0        2                      1   \n",
       "144         231.0        4                      4   \n",
       "145         231.0        4                      4   \n",
       "\n",
       "     maint_order_activities_type  is_sistematic  priority  \\\n",
       "19                             1              0         1   \n",
       "20                             1              0         1   \n",
       "21                             1              0         3   \n",
       "144                            1              0         1   \n",
       "145                            1              0         1   \n",
       "\n",
       "     maint_order_status_id  \n",
       "19                       1  \n",
       "20                       1  \n",
       "21                       3  \n",
       "144                      3  \n",
       "145                      3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_table_full.groupby(['priority','maint_order_status_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_full.to_csv(dir_save+table+\"_etl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_table_full.groupby(['user_text']).size()\n",
    "# df_table_full[df_table_full['user_text'].str.contains(\"testes\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df_table_full.columns:\n",
    "#     print(column)\n",
    "#     display(df_table_full.groupby([column]).size().reset_index(name='count').sort_values(by=['count'],ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_percentage(df, columns):\n",
    "    \"\"\"\n",
    "    This function returns the number of different elements in each column as a percentage of the total elements in the group.\n",
    "    A low value indicates there are many repeated elements.\n",
    "    Example 1: a value of 0 indicates all values are the same.\n",
    "    Example 2: a value of 100 indicates all values are different.\n",
    "    \"\"\"\n",
    "    diversity = dict()\n",
    "\n",
    "    for col in columns:\n",
    "        diversity[col] = len(df[col].unique())\n",
    "\n",
    "    diversity_series = pd.Series(diversity)\n",
    "    return (diversity_series/len(df)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_percentage(df_table_full,df_table_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = data.isna().mean()\n",
    "total_missing = data.isna().sum()\n",
    "\n",
    "missing_value_df = pd.DataFrame({'column_name': data.columns,\n",
    "                                 'total_missing': total_missing,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df = missing_value_df.reset_index();\n",
    "missing_value_df = missing_value_df.drop('index',axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
