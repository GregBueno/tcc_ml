{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 50\n",
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred);\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "        \n",
    "    fig, ax = plt.subplots(1,1, figsize=(10,8))\n",
    "    \n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap,vmin=0,vmax=1)\n",
    "    \n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.ax.tick_params(labelsize=15) \n",
    "#     ax.figure.colorbar(im, ax=ax)\n",
    "#     ax.tick_params(labelsize=10) \n",
    "    \n",
    "    # We want to show all ticks...\n",
    "    _ = ax.set_ylabel('True Label', fontsize=20)\n",
    "    _ = ax.set_xlabel('Predicted Label', fontsize=20)\n",
    "    _ = ax.set_xticklabels(classes,fontsize=20)\n",
    "    _ = ax.set_yticklabels(classes,fontsize=20)\n",
    "    _ = ax.set_title(title, fontsize=22)\n",
    "    \n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes)\n",
    "#            title=title,\n",
    "#            ylabel='True label',\n",
    "#            xlabel='Predicted label')\n",
    "     \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\",fontsize=15)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    #fig.savefig('./img.png',dpi = 300)   # save the figure to file\n",
    "#     plt.close(fig)    # close the figure window\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freq(df, col, top_classes=20):\n",
    "    \"\"\"\n",
    "    :param df: dataframe\n",
    "    :param col: list of label string\n",
    "    :param top_classes: (integer) Plot top labels only.\n",
    "    \"\"\"\n",
    "    sns.set_style('whitegrid')\n",
    "\n",
    "    col = col\n",
    "    data = df[~df[col].isnull().any(axis=1)]\n",
    "    data = data.set_index(col)\n",
    "    \n",
    "    # Check out the frequency over each concept.\n",
    "    freq = pd.DataFrame({\n",
    "            'freq': data.index.value_counts(normalize=True),\n",
    "            'count': data.index.value_counts(normalize=False)},\n",
    "            index=data.index.value_counts(normalize=True).index)\n",
    "    print('Frequency(Top {})...'.format(top_classes))\n",
    "    freq = freq[:top_classes]\n",
    "    display(freq)\n",
    "    \n",
    "    # Plot bar chart.\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "    _ = freq.plot(y='freq', kind='bar', ax=ax, legend=False, colormap='Set2')\n",
    "    _ = ax.set_ylabel('frequency', fontsize='x-large')\n",
    "    _ = ax.set_xticklabels(freq.index.values, rotation=40, ha='right')\n",
    "    _ = ax.set_title('Frequency over Each Class', fontsize='x-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate \n",
    "\n",
    "pathFile = './resource/maint_order_evaluate.csv'\n",
    "df_eval = pd.read_csv(pathFile, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnToClassify = 'priority'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_full = pd.read_csv(\"./resource/maint_order_process.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193005, 84)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>141982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   priority   count\n",
       "0         1  141982\n",
       "1         2   19733\n",
       "2         3   17652\n",
       "3         4    9092\n",
       "4         5    4546"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table_full.groupby('priority').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_table_full.groupby(['priority']).size().reset_index(name='count').sort_values(by=['count'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "_ = df_plot.plot(y='count', kind='bar', ax=ax, legend=False, colormap='Set2')\n",
    "_ = ax.set_ylabel('Count', fontsize='x-large')\n",
    "_ = ax.set_xlabel('Label', fontsize='x-large')\n",
    "_ = ax.set_xticklabels(df_plot.priority.values, rotation=40, ha='right')\n",
    "_ = ax.set_title('Data Count by Class', fontsize='x-large')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for column in df_table_full.columns:\n",
    "    print(column)\n",
    "    display(df_table_full.groupby([column]).size().reset_index(name='count').sort_values(by=['count'],ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPSIS Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topsis = pd.read_csv('./resource/output_topsis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topsis = df_topsis[df_topsis.col!='priority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topsis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>typevalue</th>\n",
       "      <th>usenull</th>\n",
       "      <th>p_null</th>\n",
       "      <th>p_unique</th>\n",
       "      <th>p_max_row_class</th>\n",
       "      <th>rank_topsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>third_loc_id</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>0.031963</td>\n",
       "      <td>0.979647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>second_loc_id</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026155</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>0.067071</td>\n",
       "      <td>0.966268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cost_center_id</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.068382</td>\n",
       "      <td>0.965746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asset_id</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.051905</td>\n",
       "      <td>0.031693</td>\n",
       "      <td>0.959837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asset_group_id</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.089459</td>\n",
       "      <td>0.955425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              col  typevalue  usenull    p_null  p_unique  p_max_row_class  \\\n",
       "0    third_loc_id        1.0      1.0  0.033937  0.013533         0.031963   \n",
       "1   second_loc_id        1.0      1.0  0.026155  0.003212         0.067071   \n",
       "2  cost_center_id        1.0      1.0  0.025989  0.001264         0.068382   \n",
       "3        asset_id        1.0      1.0  0.025901  0.051905         0.031693   \n",
       "4  asset_group_id        1.0      1.0  0.025901  0.006580         0.089459   \n",
       "\n",
       "   rank_topsis  \n",
       "0     0.979647  \n",
       "1     0.966268  \n",
       "2     0.965746  \n",
       "3     0.959837  \n",
       "4     0.955425  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topsis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_exclude = ['cancel_user_id','origin_doc','prog_year_week_number','maint_order_cancel_reason_id',\n",
    "                'total_cost','rpn','what','when','who','why','how','maint_order_on_hold_reason_id','performed_worktime',\n",
    "                'estimated_worktime','performed_asset_downtime','id_mobile','mobile_uuid','rework_cos','index',\n",
    "                'priority_calculated','maint_req_priority','maint_req_id',\n",
    "                'user_text','scheduled_to_origin','est_finish_at','scheduled_to','est_finish_at_origin','logged_user_id']\n",
    "\n",
    "df_exclude = df_table_full\n",
    "\n",
    "for i in list_exclude:\n",
    "    try:\n",
    "        df_exclude = df_exclude.drop(i, axis=1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topsis = df_topsis[df_topsis.col.isin(df_exclude.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topsis = df_topsis.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns based in condition\n",
    "df_select = df_topsis.query(\"p_null < 0.5 and p_unique < 0.5 and p_max_row_class < 0.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cols = {\n",
    "    \"topsis5\" : list(df_topsis[:5].col.values) ,\n",
    "    \"topsis10\" : list(df_topsis[:10].col.values) ,\n",
    "    \"topsis15\" : list(df_topsis[:15].col.values) ,\n",
    "    \"topsis20\" : list(df_topsis[:20].col.values) ,\n",
    "    \"topsis25\" : list(df_topsis[:25].col.values) ,\n",
    "    \"manualcols\" : list(df_select.col.values)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Field Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Table Normalized or Table Raw\n",
    "# df_table = pd.concat(list_df)\n",
    "df_table = df_table_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field Labels  [1 3 5 2 4]\n",
      "Table Thape  (193005, 84)\n"
     ]
    }
   ],
   "source": [
    "print('Field Labels ', df_table[columnToClassify].unique())\n",
    "print('Table Thape ',df_table.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func Process Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Options \n",
    "------\n",
    "topsis5 topsis10 topsis15 topsis20 topsis25 manualcols\n",
    "\"\"\"\n",
    "def process_df_ml(df_raw, columnToClassify, cols_list):\n",
    "    \n",
    "    df_table = df_raw[[columnToClassify,*cols_list]]\n",
    "\n",
    "    previsores = df_table.drop(columnToClassify, axis=1)\n",
    "    classe = df_table[[columnToClassify]]\n",
    "\n",
    "    previsores_names = list(df_table.drop(columnToClassify, axis=1).columns)\n",
    "    class_names = df_table[columnToClassify].unique().astype(str)\n",
    "\n",
    "    _,cols = previsores.shape\n",
    "\n",
    "    # Features Transform\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    labelencoder_previsores = LabelEncoder()\n",
    "    for i in previsores.columns:\n",
    "        previsores[i] = labelencoder_previsores.fit_transform(previsores[i])\n",
    "\n",
    "#     labelencoder_classe = LabelEncoder()\n",
    "#     classe[columnToClassify] = labelencoder_classe.fit_transform(classe[columnToClassify])\n",
    "    \n",
    "    # Split Dataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(previsores, classe, test_size=0.30, random_state=0)\n",
    "\n",
    "    # Smote / Near Miss\n",
    "    \n",
    "#     from imblearn.over_sampling import SMOTE\n",
    "#     smt = SMOTE()\n",
    "#     X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "#     from imblearn.under_sampling import NearMiss\n",
    "\n",
    "#     nr = NearMiss()\n",
    "#     X_train, y_train = nr.fit_sample(X_train, y_train)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test # , labelencoder_classe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Func to ML Evaluate\n",
    "def process_df_ml_test(df_raw, columnToClassify, cols_list):\n",
    "    \n",
    "    df_table = df_raw[[columnToClassify,*cols_list]]\n",
    "\n",
    "    previsores = df_table.drop(columnToClassify, axis=1)\n",
    "    classe = df_table[[columnToClassify]]\n",
    "\n",
    "    previsores_names = list(df_table.drop(columnToClassify, axis=1).columns)\n",
    "    class_names = df_table[columnToClassify].unique().astype(str)\n",
    "\n",
    "    _,cols = previsores.shape\n",
    "\n",
    "    # Features Transform\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    labelencoder_previsores = LabelEncoder()\n",
    "    for i in previsores.columns:\n",
    "        previsores[i] = labelencoder_previsores.fit_transform(previsores[i])\n",
    "\n",
    "#     labelencoder_classe = LabelEncoder()\n",
    "#     classe[columnToClassify] = labelencoder_classe.fit_transform(classe[columnToClassify])\n",
    "    \n",
    "    return previsores, classe #, labelencoder_classe.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Varius Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "from sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "#load package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "#     svm.SVC(probability=True),\n",
    "    tree.DecisionTreeClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================\n",
      "\u001b[1mRandomForestClassifier\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis5\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.97      0.88     42505\n",
      "           2       0.61      0.33      0.43      5967\n",
      "           3       0.71      0.35      0.47      5419\n",
      "           4       0.45      0.16      0.23      2664\n",
      "           5       0.68      0.08      0.15      1347\n",
      "\n",
      "    accuracy                           0.79     57902\n",
      "   macro avg       0.65      0.38      0.43     57902\n",
      "weighted avg       0.76      0.79      0.75     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.91      0.68        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.51       100\n",
      "   macro avg       0.18      0.30      0.23       100\n",
      "weighted avg       0.30      0.51      0.38       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis10\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.97      0.96     42505\n",
      "           2       0.72      0.68      0.70      5967\n",
      "           3       0.72      0.67      0.69      5419\n",
      "           4       0.77      0.76      0.76      2664\n",
      "           5       0.67      0.54      0.60      1347\n",
      "\n",
      "    accuracy                           0.89     57902\n",
      "   macro avg       0.76      0.72      0.74     57902\n",
      "weighted avg       0.89      0.89      0.89     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis15\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.98      0.97     42505\n",
      "           2       0.79      0.73      0.76      5967\n",
      "           3       0.77      0.72      0.75      5419\n",
      "           4       0.80      0.79      0.79      2664\n",
      "           5       0.74      0.60      0.66      1347\n",
      "\n",
      "    accuracy                           0.91     57902\n",
      "   macro avg       0.81      0.76      0.79     57902\n",
      "weighted avg       0.91      0.91      0.91     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis20\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.98      0.97     42505\n",
      "           2       0.80      0.73      0.76      5967\n",
      "           3       0.78      0.72      0.75      5419\n",
      "           4       0.81      0.79      0.80      2664\n",
      "           5       0.75      0.60      0.67      1347\n",
      "\n",
      "    accuracy                           0.91     57902\n",
      "   macro avg       0.82      0.77      0.79     57902\n",
      "weighted avg       0.91      0.91      0.91     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis25\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.98      0.97     42505\n",
      "           2       0.79      0.73      0.76      5967\n",
      "           3       0.78      0.72      0.75      5419\n",
      "           4       0.81      0.79      0.80      2664\n",
      "           5       0.74      0.61      0.67      1347\n",
      "\n",
      "    accuracy                           0.91     57902\n",
      "   macro avg       0.81      0.77      0.79     57902\n",
      "weighted avg       0.91      0.91      0.91     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mmanualcols\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.96      0.91     42505\n",
      "           2       0.72      0.53      0.61      5967\n",
      "           3       0.64      0.45      0.53      5419\n",
      "           4       0.51      0.38      0.43      2664\n",
      "           5       0.57      0.18      0.27      1347\n",
      "\n",
      "    accuracy                           0.82     57902\n",
      "   macro avg       0.66      0.50      0.55     57902\n",
      "weighted avg       0.80      0.82      0.80     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.98      0.72        56\n",
      "           2       0.75      0.09      0.17        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.58       100\n",
      "   macro avg       0.44      0.36      0.30       100\n",
      "weighted avg       0.56      0.58      0.46       100\n",
      "\n",
      "===================================================================================================\n",
      "\u001b[1mLogisticRegressionCV\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis5\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.99      0.84     42505\n",
      "           2       0.00      0.00      0.00      5967\n",
      "           3       0.09      0.00      0.01      5419\n",
      "           4       0.00      0.00      0.00      2664\n",
      "           5       0.00      0.00      0.00      1347\n",
      "\n",
      "    accuracy                           0.73     57902\n",
      "   macro avg       0.16      0.20      0.17     57902\n",
      "weighted avg       0.55      0.73      0.62     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis10\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.94      0.84     42505\n",
      "           2       0.30      0.15      0.20      5967\n",
      "           3       0.48      0.14      0.22      5419\n",
      "           4       0.00      0.00      0.00      2664\n",
      "           5       0.00      0.00      0.00      1347\n",
      "\n",
      "    accuracy                           0.72     57902\n",
      "   macro avg       0.31      0.25      0.25     57902\n",
      "weighted avg       0.63      0.72      0.65     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis15\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.95      0.85     42505\n",
      "           2       0.43      0.18      0.25      5967\n",
      "           3       0.55      0.15      0.24      5419\n",
      "           4       0.70      0.30      0.42      2664\n",
      "           5       0.02      0.00      0.00      1347\n",
      "\n",
      "    accuracy                           0.75     57902\n",
      "   macro avg       0.49      0.32      0.35     57902\n",
      "weighted avg       0.69      0.75      0.69     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.32      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis20\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.96      0.85     42505\n",
      "           2       0.42      0.14      0.21      5967\n",
      "           3       0.45      0.11      0.17      5419\n",
      "           4       0.70      0.30      0.42      2664\n",
      "           5       0.02      0.00      0.00      1347\n",
      "\n",
      "    accuracy                           0.74     57902\n",
      "   macro avg       0.47      0.30      0.33     57902\n",
      "weighted avg       0.68      0.74      0.68     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.32      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis25\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.97      0.85     42505\n",
      "           2       0.39      0.12      0.19      5967\n",
      "           3       0.41      0.06      0.11      5419\n",
      "           4       0.78      0.30      0.43      2664\n",
      "           5       0.00      0.00      0.00      1347\n",
      "\n",
      "    accuracy                           0.74     57902\n",
      "   macro avg       0.47      0.29      0.31     57902\n",
      "weighted avg       0.67      0.74      0.67     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.32      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mmanualcols\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.99      0.86     42505\n",
      "           2       0.84      0.07      0.13      5967\n",
      "           3       0.70      0.25      0.37      5419\n",
      "           4       0.00      0.00      0.00      2664\n",
      "           5       0.00      0.00      0.00      1347\n",
      "\n",
      "    accuracy                           0.76     57902\n",
      "   macro avg       0.46      0.26      0.27     57902\n",
      "weighted avg       0.71      0.76      0.68     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "===================================================================================================\n",
      "\u001b[1mGaussianNB\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis5\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.06      0.11     42505\n",
      "           2       0.14      0.62      0.23      5967\n",
      "           3       0.23      0.28      0.25      5419\n",
      "           4       0.08      0.23      0.12      2664\n",
      "           5       0.06      0.64      0.11      1347\n",
      "\n",
      "    accuracy                           0.16     57902\n",
      "   macro avg       0.28      0.37      0.16     57902\n",
      "weighted avg       0.71      0.16      0.13     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        56\n",
      "           2       0.32      1.00      0.48        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.32       100\n",
      "   macro avg       0.11      0.33      0.16       100\n",
      "weighted avg       0.10      0.32      0.16       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis10\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.05      0.09     42505\n",
      "           2       0.15      0.64      0.24      5967\n",
      "           3       0.20      0.30      0.24      5419\n",
      "           4       0.44      0.18      0.25      2664\n",
      "           5       0.05      0.79      0.10      1347\n",
      "\n",
      "    accuracy                           0.16     57902\n",
      "   macro avg       0.35      0.39      0.18     57902\n",
      "weighted avg       0.73      0.16      0.13     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        56\n",
      "           2       0.32      1.00      0.48        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.32       100\n",
      "   macro avg       0.11      0.33      0.16       100\n",
      "weighted avg       0.10      0.32      0.16       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis15\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.14      0.24     42505\n",
      "           2       0.17      0.61      0.27      5967\n",
      "           3       0.19      0.40      0.25      5419\n",
      "           4       0.34      0.70      0.46      2664\n",
      "           5       0.06      0.66      0.12      1347\n",
      "\n",
      "    accuracy                           0.25     57902\n",
      "   macro avg       0.35      0.50      0.27     57902\n",
      "weighted avg       0.76      0.25      0.25     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        56\n",
      "           2       0.32      1.00      0.48        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.32       100\n",
      "   macro avg       0.11      0.33      0.16       100\n",
      "weighted avg       0.10      0.32      0.16       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis20\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.13      0.23     42505\n",
      "           2       0.20      0.54      0.29      5967\n",
      "           3       0.15      0.44      0.22      5419\n",
      "           4       0.24      0.74      0.36      2664\n",
      "           5       0.06      0.50      0.11      1347\n",
      "\n",
      "    accuracy                           0.24     57902\n",
      "   macro avg       0.32      0.47      0.24     57902\n",
      "weighted avg       0.76      0.24      0.24     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        56\n",
      "           2       0.32      1.00      0.48        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.32       100\n",
      "   macro avg       0.11      0.33      0.16       100\n",
      "weighted avg       0.10      0.32      0.16       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis25\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.12      0.21     42505\n",
      "           2       0.21      0.45      0.29      5967\n",
      "           3       0.14      0.48      0.22      5419\n",
      "           4       0.19      0.81      0.31      2664\n",
      "           5       0.05      0.37      0.09      1347\n",
      "\n",
      "    accuracy                           0.22     57902\n",
      "   macro avg       0.31      0.45      0.22     57902\n",
      "weighted avg       0.76      0.22      0.22     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        56\n",
      "           2       0.32      1.00      0.48        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.32       100\n",
      "   macro avg       0.11      0.33      0.16       100\n",
      "weighted avg       0.10      0.32      0.16       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mmanualcols\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.46      0.63     42505\n",
      "           2       0.33      0.46      0.39      5967\n",
      "           3       0.29      0.33      0.31      5419\n",
      "           4       0.09      0.31      0.14      2664\n",
      "           5       0.07      0.79      0.13      1347\n",
      "\n",
      "    accuracy                           0.45     57902\n",
      "   macro avg       0.36      0.47      0.32     57902\n",
      "weighted avg       0.80      0.45      0.54     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.04      0.07        56\n",
      "           2       0.33      1.00      0.50        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.34       100\n",
      "   macro avg       0.44      0.35      0.19       100\n",
      "weighted avg       0.67      0.34      0.20       100\n",
      "\n",
      "===================================================================================================\n",
      "\u001b[1mKNeighborsClassifier\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis5\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.95      0.87     42505\n",
      "           2       0.54      0.35      0.43      5967\n",
      "           3       0.59      0.36      0.45      5419\n",
      "           4       0.44      0.12      0.18      2664\n",
      "           5       0.55      0.09      0.15      1347\n",
      "\n",
      "    accuracy                           0.77     57902\n",
      "   macro avg       0.59      0.37      0.42     57902\n",
      "weighted avg       0.74      0.77      0.74     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis10\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.95      0.92     42505\n",
      "           2       0.62      0.53      0.57      5967\n",
      "           3       0.66      0.55      0.60      5419\n",
      "           4       0.76      0.71      0.73      2664\n",
      "           5       0.50      0.32      0.39      1347\n",
      "\n",
      "    accuracy                           0.84     57902\n",
      "   macro avg       0.69      0.61      0.64     57902\n",
      "weighted avg       0.83      0.84      0.84     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis15\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.95      0.92     42505\n",
      "           2       0.62      0.52      0.57      5967\n",
      "           3       0.68      0.57      0.62      5419\n",
      "           4       0.77      0.71      0.74      2664\n",
      "           5       0.55      0.36      0.43      1347\n",
      "\n",
      "    accuracy                           0.85     57902\n",
      "   macro avg       0.70      0.62      0.66     57902\n",
      "weighted avg       0.83      0.85      0.84     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis20\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.95      0.92     42505\n",
      "           2       0.62      0.52      0.56      5967\n",
      "           3       0.68      0.56      0.61      5419\n",
      "           4       0.77      0.71      0.74      2664\n",
      "           5       0.57      0.37      0.45      1347\n",
      "\n",
      "    accuracy                           0.84     57902\n",
      "   macro avg       0.70      0.62      0.66     57902\n",
      "weighted avg       0.83      0.84      0.84     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis25\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.95      0.92     42505\n",
      "           2       0.62      0.51      0.56      5967\n",
      "           3       0.67      0.55      0.61      5419\n",
      "           4       0.77      0.71      0.74      2664\n",
      "           5       0.56      0.37      0.45      1347\n",
      "\n",
      "    accuracy                           0.84     57902\n",
      "   macro avg       0.70      0.62      0.66     57902\n",
      "weighted avg       0.83      0.84      0.84     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      1.00      0.72        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mmanualcols\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.95      0.90     42505\n",
      "           2       0.64      0.52      0.57      5967\n",
      "           3       0.56      0.42      0.48      5419\n",
      "           4       0.50      0.33      0.40      2664\n",
      "           5       0.57      0.13      0.21      1347\n",
      "\n",
      "    accuracy                           0.81     57902\n",
      "   macro avg       0.63      0.47      0.51     57902\n",
      "weighted avg       0.78      0.81      0.79     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.98      0.71        56\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.55       100\n",
      "   macro avg       0.19      0.33      0.24       100\n",
      "weighted avg       0.31      0.55      0.40       100\n",
      "\n",
      "===================================================================================================\n",
      "\u001b[1mDecisionTreeClassifier\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis5\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.97      0.88     42505\n",
      "           2       0.61      0.34      0.44      5967\n",
      "           3       0.72      0.34      0.46      5419\n",
      "           4       0.47      0.14      0.21      2664\n",
      "           5       0.74      0.08      0.15      1347\n",
      "\n",
      "    accuracy                           0.79     57902\n",
      "   macro avg       0.67      0.37      0.43     57902\n",
      "weighted avg       0.76      0.79      0.75     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.70      0.63        56\n",
      "           2       0.12      0.12      0.12        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.43       100\n",
      "   macro avg       0.23      0.27      0.25       100\n",
      "weighted avg       0.36      0.43      0.39       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis10\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.95      0.95     42505\n",
      "           2       0.66      0.66      0.66      5967\n",
      "           3       0.67      0.67      0.67      5419\n",
      "           4       0.73      0.75      0.74      2664\n",
      "           5       0.55      0.56      0.55      1347\n",
      "\n",
      "    accuracy                           0.87     57902\n",
      "   macro avg       0.71      0.72      0.71     57902\n",
      "weighted avg       0.87      0.87      0.87     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.96      0.76        56\n",
      "           2       0.85      0.34      0.49        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.65       100\n",
      "   macro avg       0.49      0.44      0.41       100\n",
      "weighted avg       0.62      0.65      0.58       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis15\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.96      0.96     42505\n",
      "           2       0.72      0.72      0.72      5967\n",
      "           3       0.70      0.70      0.70      5419\n",
      "           4       0.75      0.74      0.74      2664\n",
      "           5       0.62      0.61      0.62      1347\n",
      "\n",
      "    accuracy                           0.89     57902\n",
      "   macro avg       0.75      0.75      0.75     57902\n",
      "weighted avg       0.89      0.89      0.89     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.54      0.47        56\n",
      "           2       0.33      0.03      0.06        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.31       100\n",
      "   macro avg       0.25      0.19      0.18       100\n",
      "weighted avg       0.34      0.31      0.28       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis20\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.96      0.96     42505\n",
      "           2       0.71      0.72      0.72      5967\n",
      "           3       0.71      0.70      0.71      5419\n",
      "           4       0.75      0.75      0.75      2664\n",
      "           5       0.62      0.61      0.61      1347\n",
      "\n",
      "    accuracy                           0.89     57902\n",
      "   macro avg       0.75      0.75      0.75     57902\n",
      "weighted avg       0.89      0.89      0.89     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.88      0.67        56\n",
      "           2       0.33      0.03      0.06        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.50       100\n",
      "   macro avg       0.29      0.30      0.24       100\n",
      "weighted avg       0.41      0.50      0.39       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mtopsis25\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.96      0.96     42505\n",
      "           2       0.71      0.72      0.71      5967\n",
      "           3       0.71      0.70      0.70      5419\n",
      "           4       0.75      0.76      0.75      2664\n",
      "           5       0.63      0.61      0.62      1347\n",
      "\n",
      "    accuracy                           0.89     57902\n",
      "   macro avg       0.75      0.75      0.75     57902\n",
      "weighted avg       0.89      0.89      0.89     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.68      0.57        56\n",
      "           2       0.33      0.03      0.06        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.39       100\n",
      "   macro avg       0.28      0.24      0.21       100\n",
      "weighted avg       0.38      0.39      0.34       100\n",
      "\n",
      "\n",
      "\n",
      " DATASET: \u001b[1mmanualcols\u001b[0m\n",
      "\n",
      "\n",
      " ==> Classification Report in Test Data\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.96      0.90     42505\n",
      "           2       0.72      0.52      0.60      5967\n",
      "           3       0.65      0.44      0.53      5419\n",
      "           4       0.52      0.35      0.42      2664\n",
      "           5       0.56      0.18      0.27      1347\n",
      "\n",
      "    accuracy                           0.82     57902\n",
      "   macro avg       0.66      0.49      0.55     57902\n",
      "weighted avg       0.80      0.82      0.80     57902\n",
      "\n",
      "\n",
      " ==> Classification Report in Evaluation Data \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.34      0.39        56\n",
      "           2       0.12      0.16      0.14        32\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24       100\n",
      "   macro avg       0.14      0.12      0.13       100\n",
      "weighted avg       0.29      0.24      0.26       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MLA_columns = []\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "\n",
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "    print(\"===================================================================================================\")\n",
    "    print(BOLD+alg.__class__.__name__+END)\n",
    "    print('\\n')\n",
    "    for key in dict_cols.keys():\n",
    "        print('\\n\\n DATASET: '+BOLD+key+END+'\\n')\n",
    "        try: \n",
    "            \n",
    "            X_train, X_test, y_train, y_test = process_df_ml(df_table, columnToClassify, dict_cols[key])\n",
    "\n",
    "            predicted_test = alg.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "            X_eval, y_eval = process_df_ml_test(df_eval, columnToClassify, dict_cols[key])\n",
    "\n",
    "            predicted_eval = alg.predict(X_eval)\n",
    "        \n",
    "            print('\\n ==> Classification Report in Test Data\\n')\n",
    "            class_report = classification_report(y_test, predicted_test)\n",
    "            print(class_report)\n",
    "            \n",
    "            print('\\n ==> Classification Report in Evaluation Data \\n')\n",
    "            class_report_eval = classification_report(y_eval, predicted_eval)\n",
    "            print(class_report_eval)\n",
    "            \n",
    "            \n",
    "            MLA_name = alg.__class__.__name__\n",
    "            MLA_compare.loc[row_index, 'Data_Mode'] = key\n",
    "            MLA_compare.loc[row_index, 'MLA_Name'] = MLA_name\n",
    "            MLA_compare.loc[row_index, 'MLA_Train_Accuracy'] = round(alg.score(X_train, y_train), 4)\n",
    "            MLA_compare.loc[row_index, 'MLA_Test_Accuracy'] = round(accuracy_score(y_test, predicted_test), 4)\n",
    "            MLA_compare.loc[row_index, 'MLA_Eval_Accuracy'] = round(accuracy_score(y_eval, predicted_eval), 4)\n",
    "            row_index+=1\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "MLA_compare.sort_values(by = ['MLA_Test_Accuracy'], ascending = False, inplace = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLA_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.pivot_table(MLA_compare, \n",
    "                     \n",
    "                        values=['MLA_Test_Accuracy'], #,'MLA_Test_Accuracy','MLA_Eval_Accuracy'\n",
    "                        index=['MLA_Name'],\n",
    "                        columns=['Data_Mode'],\n",
    "                        fill_value=0).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MLA_Name</th>\n",
       "      <th colspan=\"6\" halign=\"left\">MLA_Test_Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_Mode</th>\n",
       "      <th></th>\n",
       "      <th>manualcols</th>\n",
       "      <th>topsis10</th>\n",
       "      <th>topsis15</th>\n",
       "      <th>topsis20</th>\n",
       "      <th>topsis25</th>\n",
       "      <th>topsis5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.8201</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.7865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.4469</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>0.2469</td>\n",
       "      <td>0.2409</td>\n",
       "      <td>0.2246</td>\n",
       "      <td>0.1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.8449</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.7724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.7196</td>\n",
       "      <td>0.7468</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.7412</td>\n",
       "      <td>0.7301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.8207</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.7856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA_Name MLA_Test_Accuracy                    \\\n",
       "Data_Mode                                manualcols topsis10 topsis15   \n",
       "0          DecisionTreeClassifier            0.8201   0.8738   0.8926   \n",
       "1                      GaussianNB            0.4469   0.1563   0.2469   \n",
       "2            KNeighborsClassifier            0.8055   0.8432   0.8460   \n",
       "3            LogisticRegressionCV            0.7566   0.7196   0.7468   \n",
       "4          RandomForestClassifier            0.8207   0.8896   0.9124   \n",
       "\n",
       "                                     \n",
       "Data_Mode topsis20 topsis25 topsis5  \n",
       "0           0.8925   0.8920  0.7865  \n",
       "1           0.2409   0.2246  0.1573  \n",
       "2           0.8449   0.8444  0.7724  \n",
       "3           0.7430   0.7412  0.7301  \n",
       "4           0.9133   0.9125  0.7856  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
